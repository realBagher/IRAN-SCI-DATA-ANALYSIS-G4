{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_Urbun(sheet):\n",
    "    df_urban = {}\n",
    "    years = ['98', '99', '1400', '1401']\n",
    "    for year in years:\n",
    "        file_name = f'U{year}.xlsx'\n",
    "        sheet_name = f'U{year}{sheet}'\n",
    "        df = pd.read_excel(file_name, sheet_name = sheet_name)\n",
    "        df_urban[f'U{year}'] = df\n",
    "    return df_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_Rural(sheet):\n",
    "    df_Rural = {}\n",
    "    years = ['98', '99', '1400', '1401']\n",
    "    for year in years:\n",
    "        file_name = f'R{year}.xlsx'\n",
    "        sheet_name = f'R{year}{sheet}'\n",
    "        df = pd.read_excel(file_name, sheet_name = sheet_name)\n",
    "        df_Rural[f'R{year}'] = df\n",
    "    return df_Rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_Data = load_data_Rural('Data')\n",
    "Urbun_Data = load_data_Urbun('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_data_income_paid_jobs = load_data_Rural('P4S01')\n",
    "Urbun_data_income_paid_jobs = load_data_Urbun('P4S01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_data_income_freelance_jobs = load_data_Rural('P4S02')\n",
    "Urbun_data_income_freelance_jobs = load_data_Urbun('P4S02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_data_income_Miscellaneous = load_data_Rural('P4S03')\n",
    "Urbun_data_income_Miscellaneous = load_data_Urbun('P4S03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_data_income_subsidy = load_data_Rural('P4S04')\n",
    "Urbun_data_income_subsidy = load_data_Urbun('P4S04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_address = {}\n",
    "for key, value in Rural_Data.items():\n",
    "    Selected_address[key] = value[value['province'] == 'CharmahalBakhtiari']['Address'].unique()\n",
    "\n",
    "for key, value in Urbun_Data.items():\n",
    "    Selected_address[key] = value[value['province'] == 'CharmahalBakhtiari']['Address'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paid jobs\n",
    "for key, value in Rural_data_income_paid_jobs.items():\n",
    "    Rural_data_income_paid_jobs[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "for key, value in Urbun_data_income_paid_jobs.items():\n",
    "    Urbun_data_income_paid_jobs[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "\n",
    "# Freelance jobs\n",
    "for key, value in Rural_data_income_freelance_jobs.items():\n",
    "    Rural_data_income_freelance_jobs[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "for key, value in Urbun_data_income_freelance_jobs.items():\n",
    "    Urbun_data_income_freelance_jobs[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "\n",
    "# Miscellaneous\n",
    "for key, value in Rural_data_income_Miscellaneous.items():\n",
    "    Rural_data_income_Miscellaneous[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "for key, value in Urbun_data_income_Miscellaneous.items():\n",
    "    Urbun_data_income_Miscellaneous[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "\n",
    "# Subsidy\n",
    "for key, value in Rural_data_income_subsidy.items():\n",
    "    Rural_data_income_subsidy[key] = value[value['Address'].isin(Selected_address[key])]\n",
    "for key, value in Urbun_data_income_subsidy.items():\n",
    "    Urbun_data_income_subsidy[key] = value[value['Address'].isin(Selected_address[key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Urbun_data_income_freelance_jobs['U1401']['income_s_y'] = Urbun_data_income_freelance_jobs['U1401']['income_s_y'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rural_data_income_freelance_jobs['R1401'].loc[1571, 'income_s_y'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in Urbun_data_income_Miscellaneous.items() :\n",
    "    for col, value_d in value.dtypes.items() :\n",
    "        if value_d == 'object' :\n",
    "            Urbun_data_income_Miscellaneous[key][col] = value[col].fillna(0).astype('float')\n",
    "\n",
    "for key, value in Rural_data_income_Miscellaneous.items() :\n",
    "    for col, value_d in value.dtypes.items() :\n",
    "        if value_d == 'object' :\n",
    "            Rural_data_income_Miscellaneous[key][col] = value[col].fillna(0).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in Urbun_data_income_subsidy.items() :\n",
    "    for col, value_d in value.dtypes.items() :\n",
    "        if value_d == 'object' :\n",
    "            Urbun_data_income_subsidy[key][col] = value[col].fillna(0).astype('float')\n",
    "\n",
    "for key, value in Rural_data_income_subsidy.items() :\n",
    "    for col, value_d in value.dtypes.items() :\n",
    "        if value_d == 'object' :\n",
    "            Rural_data_income_subsidy[key][col] = value[col].fillna(0).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paid Jobs\n",
    "paid_jobs = {}\n",
    "for key, value in Rural_data_income_paid_jobs.items():\n",
    "    Rural_data_income_paid_jobs[key].loc[:, 'netincome_w_y'] = Rural_data_income_paid_jobs[key]['netincome_w_y'].fillna(0).astype('float')\n",
    "    paid_jobs[key] = value.groupby('Address')[['netincome_w_y']].agg('sum').reset_index()\n",
    "for key, value in Urbun_data_income_paid_jobs.items():\n",
    "    Urbun_data_income_paid_jobs[key].loc[:, 'netincome_w_y'] = Urbun_data_income_paid_jobs[key]['netincome_w_y'].fillna(0).astype('float')\n",
    "    paid_jobs[key] = value.groupby('Address')[['netincome_w_y']].agg('sum').reset_index()\n",
    "    \n",
    "# Freelance Jobs\n",
    "Freelance_Jobs = {}\n",
    "for key, value in Rural_data_income_freelance_jobs.items() :\n",
    "    Rural_data_income_freelance_jobs[key].loc[:, 'income_s_y'] = Rural_data_income_freelance_jobs[key]['income_s_y'].fillna(0).astype('float')\n",
    "    Freelance_Jobs[key] = value.groupby('Address')[['income_s_y']].agg('sum').reset_index()\n",
    "for key, value in Urbun_data_income_freelance_jobs.items() :\n",
    "    Urbun_data_income_freelance_jobs[key].loc[:, 'income_s_y'] = Urbun_data_income_freelance_jobs[key]['income_s_y'].fillna(0).astype('float')\n",
    "    Freelance_Jobs[key] = value.groupby('Address')[['income_s_y']].agg('sum').reset_index()\n",
    "    \n",
    "# Miscellaneous\n",
    "Miscellaneous = {}\n",
    "selected_columns = ['income_pension', 'income_rent', 'income_interest', 'income_aid', 'income_resale', 'income_transfer']\n",
    "for key in Rural_data_income_Miscellaneous.keys():\n",
    "    Miscellaneous[key] = Rural_data_income_Miscellaneous[key].groupby('Address')[selected_columns].agg('sum').reset_index()\n",
    "for key in Urbun_data_income_Miscellaneous.keys():\n",
    "    Miscellaneous[key] = Urbun_data_income_Miscellaneous[key].groupby('Address')[selected_columns].agg('sum').reset_index()\n",
    "    \n",
    "# Subsidy \n",
    "Subsidy = {}\n",
    "for key, value in Rural_data_income_subsidy.items():\n",
    "    Subsidy[key] = value.groupby('Address')[['subsidy']].agg('sum').reset_index()\n",
    "for key, value in Urbun_data_income_subsidy.items():\n",
    "    Subsidy[key] = value.groupby('Address')[['subsidy']].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_income_data_Urbun(years):\n",
    "    ans = {}\n",
    "    for year in years :\n",
    "        \n",
    "        df = paid_jobs[f'U{year}'].merge(Freelance_Jobs[f'U{year}'], how = 'outer')\n",
    "\n",
    "        df = df.merge(Miscellaneous[f'U{year}'], how = 'outer')\n",
    "\n",
    "        df = df.merge(Subsidy[f'U{year}'], how='outer')\n",
    "        \n",
    "        ans[f'number{year}'] = df['Address'].nunique()\n",
    "\n",
    "        df = df.drop(columns='Address')\n",
    "\n",
    "        df.dropna(how='all', inplace=True)\n",
    "\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        df = df.astype('float')\n",
    "\n",
    "        df = df.sum(axis=1)\n",
    "                \n",
    "        ans[f'{year}'] = df\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_income_data_Rural(years):\n",
    "    ans = {}\n",
    "    for year in years :\n",
    "        \n",
    "        df = paid_jobs[f'R{year}'].merge(Freelance_Jobs[f'R{year}'], how = 'outer')\n",
    "\n",
    "        df = df.merge(Miscellaneous[f'R{year}'], how = 'outer')\n",
    "\n",
    "        df = df.merge(Subsidy[f'R{year}'], how='outer')\n",
    "        \n",
    "        ans[f'number{year}'] = df['Address'].nunique()\n",
    "\n",
    "        df = df.drop(columns='Address')\n",
    "\n",
    "        df.dropna(how='all', inplace=True)\n",
    "\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        df = df.astype('float')\n",
    "\n",
    "        df = df.sum(axis=1)\n",
    "                \n",
    "        ans[f'{year}'] = df\n",
    "            \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legion\\AppData\\Local\\Temp\\ipykernel_2852\\3378569469.py:17: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "years = ['98', '99', '1400', '1401']\n",
    "Urban_data_income = process_income_data_Urbun(years)\n",
    "Rural_data_income = process_income_data_Rural(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years :\n",
    "    Urban_data_income[year].dropna(inplace=True)\n",
    "    Rural_data_income[year].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Rural_data_income['98']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فرضیات\n",
    "\n",
    "- **H0**: درآمد خانوارهای شهری و روستایی در استان چهارمحال و بختیاری با هم برابر است\n",
    "- **H1**: درآمد خانوارهای شهری و روستایی در استان چهارمحال و بختیاری با هم برابر نیست\n",
    "- **ALPHA** : 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.8730337948969712, pvalue=3.10940011587708e-19),\n",
       " ShapiroResult(statistic=0.7227596972899459, pvalue=2.114277209279307e-31))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro_R98_zscore = stats.shapiro(Rural_data_income['98'])\n",
    "shapiro_U98_zscore = stats.shapiro(Urban_data_income['98'])\n",
    "shapiro_R98_zscore, shapiro_U98_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا پی ولیو خیلی کمتر از الفا پس داده ها نرمال نیستن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=108213.0, pvalue=2.651191958137599e-17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(Rural_data_income['98'], Urban_data_income['98'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا تو آزمون \"یو\" چون \"پی ولیو\" خیلی کمتر از آلقا پس فرض صفر رد میشه و فرض متقابلش برقراه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش میکنیم داده ها رو نرمال کنیم اگه نرمال شدن نتیجه تست \"تی\" رو با تست \"یو\" مقایشه میکنیم ببینیم که آیا واقعا فرض صفر رد میشه یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.888689671015572, pvalue=5.064260624511144e-18),\n",
       " ShapiroResult(statistic=0.7558179702687562, pvalue=7.431497996659441e-30))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_98_yeojohnson , _ = stats.yeojohnson(Rural_data_income['98'])\n",
    "U_98_yeojohnson , _ = stats.yeojohnson(Urban_data_income['98'])\n",
    "shapiro_R_98_yeojohnson = stats.shapiro(R_98_yeojohnson)\n",
    "shapiro_U_98_yeojohnson = stats.shapiro(U_98_yeojohnson)\n",
    "shapiro_R_98_yeojohnson, shapiro_U_98_yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9558175332181926, pvalue=1.0659530227962505e-10),\n",
       " ShapiroResult(statistic=0.9571190219039325, pvalue=8.84229456058444e-13))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_98_log = np.log(Rural_data_income['98'])\n",
    "U_98_log = np.log(Urban_data_income['98'])\n",
    "\n",
    "R_98_log = R_98_log[~np.isinf(R_98_log)]\n",
    "U_98_log = U_98_log[~np.isinf(U_98_log)]\n",
    "\n",
    "U_98_log.dropna(inplace= True)\n",
    "R_98_log.dropna(inplace= True)\n",
    "\n",
    "\n",
    "shapiro_R_98_log = stats.shapiro(R_98_log)\n",
    "shapiro_U_98_log = stats.shapiro(U_98_log)\n",
    "\n",
    "shapiro_R_98_log, shapiro_U_98_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9791868852150308, pvalue=2.7262577722556606e-06),\n",
       " ShapiroResult(statistic=0.9399689003138613, pvalue=1.779260928418208e-15))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_98_sqrt = np.sqrt(Rural_data_income['98'])\n",
    "U_98_sqrt = np.sqrt(Urban_data_income['98'])\n",
    "\n",
    "R_98_sqrt = R_98_sqrt[~np.isinf(R_98_sqrt)]\n",
    "U_98_sqrt = U_98_sqrt[~np.isinf(U_98_sqrt)]\n",
    "\n",
    "R_98_sqrt.dropna(inplace= True)\n",
    "U_98_sqrt.dropna(inplace= True)\n",
    "\n",
    "\n",
    "shapiro_R_98_sqrt = stats.shapiro(R_98_sqrt)\n",
    "shapiro_U_98_sqrt = stats.shapiro(U_98_sqrt)\n",
    "\n",
    "shapiro_R_98_sqrt, shapiro_U_98_sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش برای نرمال سازی شکست خورد پس فرض صفر همچنان رد میمونه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.829119523983219, pvalue=2.4774108583506565e-22),\n",
       " ShapiroResult(statistic=0.871013548234989, pvalue=1.6928289209323643e-22))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro_R_99 = stats.shapiro(Rural_data_income['99'])\n",
    "shapiro_U_99 = stats.shapiro(Urban_data_income['99'])\n",
    "shapiro_R_99, shapiro_U_99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا پی ولیو خیلی کمتر از الفا پس داده ها نرمال نیستن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=118671.0, pvalue=6.934803787250026e-11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(Rural_data_income['99'], Urban_data_income['99'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا تو آزمون \"یو\" چون \"پی ولیو\" خیلی کمتر از آلقا پس فرض صفر رد میشه و فرض متقابلش برقراه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش میکنیم داده ها رو نرمال کنیم اگه نرمال شدن نتیجه تست \"تی\" رو با تست \"یو\" مقایشه میکنیم ببینیم که آیا واقعا فرض صفر رد میشه یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9885980449150746, pvalue=0.0008116157218315527),\n",
       " ShapiroResult(statistic=0.8757329109706921, pvalue=4.091328419084555e-22))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_99_yeojohnson , _ = stats.yeojohnson(Rural_data_income['99'])\n",
    "U_99_yeojohnson , _ = stats.yeojohnson(Urban_data_income['99'])\n",
    "shapiro_R_99_yeojohnson = stats.shapiro(R_99_yeojohnson)\n",
    "shapiro_U_99_yeojohnson = stats.shapiro(U_99_yeojohnson)\n",
    "shapiro_R_99_yeojohnson, shapiro_U_99_yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9668133163064825, pvalue=5.457106813509286e-09),\n",
       " ShapiroResult(statistic=0.9592474727552384, pvalue=2.8918308307996402e-12))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_99_log = np.log(Rural_data_income['99'])\n",
    "U_99_log = np.log(Urban_data_income['99'])\n",
    "\n",
    "R_99_log = R_99_log[~np.isnan(R_99_log)]\n",
    "U_99_log = U_99_log[~np.isinf(U_99_log)]\n",
    "\n",
    "R_99_log = R_99_log[~np.isnan(R_99_log)]\n",
    "U_99_log = U_99_log[~np.isinf(U_99_log)]\n",
    "\n",
    "U_99_log.dropna(inplace= True)\n",
    "\n",
    "shapiro_R_99_log = stats.shapiro(R_99_log)\n",
    "shapiro_U_99_log = stats.shapiro(U_99_log)\n",
    "\n",
    "shapiro_R_99_log, shapiro_U_99_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9728331382016107, pvalue=8.2272761317294e-08),\n",
       " ShapiroResult(statistic=0.9744411425807096, pvalue=4.423530372506113e-09))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_99_sqrt = np.sqrt(Rural_data_income['99'])\n",
    "U_99_sqrt = np.sqrt(Urban_data_income['99'])\n",
    "\n",
    "U_99_sqrt = U_99_sqrt[~np.isinf(U_99_sqrt)]\n",
    "\n",
    "U_99_sqrt = U_99_sqrt[~np.isinf(U_99_sqrt)]\n",
    "\n",
    "U_99_sqrt.dropna(inplace= True)\n",
    "\n",
    "shapiro_R_99_sqrt = stats.shapiro(R_99_sqrt)\n",
    "shapiro_U_99_sqrt = stats.shapiro(U_99_sqrt)\n",
    "\n",
    "shapiro_R_99_sqrt, shapiro_U_99_sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش برای نرمال سازی شکست خورد پس فرض صفر همچنان رد میمونه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.8104428505131657, pvalue=1.3801033552846836e-23),\n",
       " ShapiroResult(statistic=0.7670912196125298, pvalue=2.3730154825564715e-29))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro_R_1400 = stats.shapiro(Rural_data_income['1400'])\n",
    "shapiro_U_1400 = stats.shapiro(Urban_data_income['1400'])\n",
    "shapiro_R_1400, shapiro_U_1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=120943.5, pvalue=1.8454659027508173e-12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(Rural_data_income['1400'], Urban_data_income['1400'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا تو آزمون \"یو\" چون \"پی ولیو\" خیلی کمتر از آلقا پس فرض صفر رد میشه و فرض متقابلش برقراه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش میکنیم داده ها رو نرمال کنیم اگه نرمال شدن نتیجه تست \"تی\" رو با تست \"یو\" مقایشه میکنیم ببینیم که آیا واقعا فرض صفر رد میشه یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9813787343631815, pvalue=6.2772685456658566e-06),\n",
       " ShapiroResult(statistic=0.9833264088667423, pvalue=9.046024448765705e-07))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1400_yeojohnson , _ = stats.yeojohnson(Rural_data_income['1400'])\n",
    "U_1400_yeojohnson , _ = stats.yeojohnson(Urban_data_income['1400'])\n",
    "shapiro_R_1400_yeojohnson = stats.shapiro(R_1400_yeojohnson)\n",
    "shapiro_U_1400_yeojohnson = stats.shapiro(U_1400_yeojohnson)\n",
    "shapiro_R_1400_yeojohnson, shapiro_U_1400_yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9581956861546164, pvalue=1.394149862677069e-10),\n",
       " ShapiroResult(statistic=0.9550926801437308, pvalue=3.403321603924779e-13))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1400_log = np.log(Rural_data_income['1400'])\n",
    "U_1400_log = np.log(Urban_data_income['1400'])\n",
    "shapiro_R_1400_log = stats.shapiro(R_1400_log)\n",
    "shapiro_U_1400_log = stats.shapiro(U_1400_log)\n",
    "shapiro_R_1400_log, shapiro_U_1400_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9631447054829181, pvalue=9.421620455935167e-10),\n",
       " ShapiroResult(statistic=0.9582678591392096, pvalue=1.2356045923664703e-12))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1400_sqrt = np.sqrt(Rural_data_income['1400'])\n",
    "U_1400_sqrt = np.sqrt(Urban_data_income['1400'])\n",
    "shapiro_R_1400_sqrt = stats.shapiro(R_1400_sqrt)\n",
    "shapiro_U_1400_sqrt = stats.shapiro(U_1400_sqrt)\n",
    "shapiro_R_1400_sqrt, shapiro_U_1400_sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش برای نرمال سازی شکست خورد پس فرض صفر همچنان رد میمونه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.8624497765713363, pvalue=2.855842062959131e-20),\n",
       " ShapiroResult(statistic=0.8955742359464116, pvalue=1.0267914922423725e-20))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro_R_1401 = stats.shapiro(Rural_data_income['1401'])\n",
    "shapiro_U_1401 = stats.shapiro(Urban_data_income['1401'])\n",
    "shapiro_R_1401, shapiro_U_1401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=122594.0, pvalue=1.3230455008288734e-11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(Rural_data_income['1401'], Urban_data_income['1401'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا تو آزمون \"یو\" چون \"پی ولیو\" خیلی کمتر از آلقا پس فرض صفر رد میشه و فرض متقابلش برقراه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش میکنیم داده ها رو نرمال کنیم اگه نرمال شدن نتیجه تست \"تی\" رو با تست \"یو\" مقایشه میکنیم ببینیم که آیا واقعا فرض صفر رد میشه یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9897078174328108, pvalue=0.0017231732480825481),\n",
       " ShapiroResult(statistic=0.9925084289817818, pvalue=0.0021912123017287194))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1401_yeojohnson , _ = stats.yeojohnson(Rural_data_income['1401'])\n",
    "U_1401_yeojohnson , _ = stats.yeojohnson(Urban_data_income['1401'])\n",
    "shapiro_R_1401_yeojohnson = stats.shapiro(R_1401_yeojohnson)\n",
    "shapiro_U_1401_yeojohnson = stats.shapiro(U_1401_yeojohnson)\n",
    "shapiro_R_1401_yeojohnson, shapiro_U_1401_yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.961430831730584, pvalue=5.413701309021109e-10),\n",
       " ShapiroResult(statistic=0.9377086643535099, pvalue=6.096595885710601e-16))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1401_log = np.log(Rural_data_income['1401'])\n",
    "U_1401_log = np.log(Urban_data_income['1401'])\n",
    "shapiro_R_1401_log = stats.shapiro(R_1401_log)\n",
    "shapiro_U_1401_log = stats.shapiro(U_1401_log)\n",
    "shapiro_R_1401_log, shapiro_U_1401_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.977374987516453, pvalue=7.322164232326638e-07),\n",
       " ShapiroResult(statistic=0.9878031647453357, pvalue=2.7290995836788253e-05))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1401_sqrt = np.sqrt(Rural_data_income['1401'])\n",
    "U_1401_sqrt = np.sqrt(Urban_data_income['1401'])\n",
    "shapiro_R_1401_sqrt = stats.shapiro(R_1401_sqrt)\n",
    "shapiro_U_1401_sqrt = stats.shapiro(U_1401_sqrt)\n",
    "shapiro_R_1401_sqrt, shapiro_U_1401_sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش برای نرمال سازی شکست خورد پس فرض صفر همچنان رد میمونه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anderson(result) :\n",
    "    print(f\"Statistic: {result.statistic}\")\n",
    "    print(f\"Critical Values: {result.critical_values}\")\n",
    "    print(f\"Significance Levels: {result.significance_level}\")\n",
    "    \n",
    "    for i in range(len(result.critical_values)):\n",
    "        if result.statistic > result.critical_values[i]:\n",
    "            print(f\"At the {result.significance_level[i]}% significance level, data is NOT normal.\")\n",
    "        else:\n",
    "            print(f\"At the {result.significance_level[i]}% significance level, data is normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_U = paid_jobs[f'U98'].merge(Freelance_Jobs[f'U98'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Miscellaneous[f'U98'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Subsidy[f'U98'], how='outer')\n",
    "\n",
    "df_U = df_U.merge(paid_jobs[f'U99'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Freelance_Jobs[f'U99'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Miscellaneous[f'U99'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Subsidy[f'U99'], how='outer')\n",
    "\n",
    "df_U = df_U.merge(paid_jobs[f'U1400'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Freelance_Jobs[f'U1400'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Miscellaneous[f'U1400'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Subsidy[f'U1400'], how='outer')\n",
    "\n",
    "df_U = df_U.merge(paid_jobs[f'U1401'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Freelance_Jobs[f'U1401'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Miscellaneous[f'U1401'], how = 'outer')\n",
    "\n",
    "df_U = df_U.merge(Subsidy[f'U1401'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Urban = df_U.drop(columns='Address').fillna(0).astype('float').sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_R = paid_jobs[f'R98'].merge(Freelance_Jobs[f'R98'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Miscellaneous[f'R98'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Subsidy[f'R98'], how='outer')\n",
    "\n",
    "df_R = df_R.merge(paid_jobs[f'R99'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Freelance_Jobs[f'R99'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Miscellaneous[f'R99'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Subsidy[f'R99'], how='outer')\n",
    "\n",
    "df_R = df_R.merge(paid_jobs[f'R1400'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Freelance_Jobs[f'R1400'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Miscellaneous[f'R1400'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Subsidy[f'R1400'], how='outer')\n",
    "\n",
    "df_R = df_R.merge(paid_jobs[f'R1401'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Freelance_Jobs[f'R1401'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Miscellaneous[f'R1401'], how = 'outer')\n",
    "\n",
    "df_R = df_R.merge(Subsidy[f'R1401'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legion\\AppData\\Local\\Temp\\ipykernel_2852\\1873862437.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  Total_Rural = df_R.drop(columns='Address').fillna(0).astype('float').sum(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "Total_Rural = df_R.drop(columns='Address').fillna(0).astype('float').sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 424.79685521963256\n",
      "Critical Values: [0.576 0.655 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n",
      "\n",
      "Statistic: 474.3031062253176\n",
      "Critical Values: [0.576 0.656 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n"
     ]
    }
   ],
   "source": [
    "anderson_Total_Rural = stats.anderson(Total_Rural)\n",
    "anderson_Total_Urban = stats.anderson(Total_Urban)\n",
    "Anderson(anderson_Total_Rural)\n",
    "print()\n",
    "Anderson(anderson_Total_Urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=13054720.5, pvalue=7.723246404175944e-10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(Total_Rural, Total_Urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- اینجا تو آزمون \"یو\" چون \"پی ولیو\" خیلی کمتر از آلقا پس فرض صفر رد میشه و فرض متقابلش برقراه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- تلاش میکنیم داده ها رو نرمال کنیم اگه نرمال شدن نتیجه تست \"تی\" رو با تست \"یو\" مقایشه میکنیم ببینیم که آیا واقعا فرض صفر رد میشه یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 383.8079699924583\n",
      "Critical Values: [0.576 0.655 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n",
      "\n",
      "Statistic: 435.75995730193426\n",
      "Critical Values: [0.576 0.656 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n"
     ]
    }
   ],
   "source": [
    "R_Total_yeojohnson , _ = stats.yeojohnson(Total_Rural)\n",
    "U_Total_yeojohnson , _ = stats.yeojohnson(Total_Urban)\n",
    "anderson_R_Total_yeojohnson = stats.anderson(R_Total_yeojohnson)\n",
    "anderson_U_Total_yeojohnson = stats.anderson(U_Total_yeojohnson)\n",
    "Anderson(anderson_R_Total_yeojohnson)\n",
    "print()\n",
    "Anderson(anderson_U_Total_yeojohnson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 44.099673005283876\n",
      "Critical Values: [0.576 0.655 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n",
      "\n",
      "Statistic: 103.88084402521963\n",
      "Critical Values: [0.576 0.656 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "d:\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "R_Total_log = np.log(Total_Rural)\n",
    "U_Total_log = np.log(Total_Urban)\n",
    "\n",
    "R_Total_log = R_Total_log[~np.isinf(R_Total_log)]\n",
    "U_Total_log = U_Total_log[~np.isinf(U_Total_log)]\n",
    "\n",
    "R_Total_log.dropna(inplace= True)\n",
    "U_Total_log.dropna(inplace= True)\n",
    "\n",
    "anderson_R_Total_log = stats.anderson(R_Total_log)\n",
    "anderson_U_Total_log = stats.anderson(U_Total_log)\n",
    "Anderson(anderson_R_Total_log)\n",
    "print()\n",
    "Anderson(anderson_U_Total_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 140.69218330856893\n",
      "Critical Values: [0.576 0.655 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n",
      "\n",
      "Statistic: 176.47888926566702\n",
      "Critical Values: [0.576 0.656 0.786 0.917 1.091]\n",
      "Significance Levels: [15.  10.   5.   2.5  1. ]\n",
      "At the 15.0% significance level, data is NOT normal.\n",
      "At the 10.0% significance level, data is NOT normal.\n",
      "At the 5.0% significance level, data is NOT normal.\n",
      "At the 2.5% significance level, data is NOT normal.\n",
      "At the 1.0% significance level, data is NOT normal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "R_Total_sqrt = np.sqrt(Total_Rural)\n",
    "U_Total_sqrt = np.sqrt(Total_Urban)\n",
    "\n",
    "R_Total_sqrt = R_Total_sqrt[~np.isinf(R_Total_sqrt)]\n",
    "U_Total_sqrt = U_Total_sqrt[~np.isinf(U_Total_sqrt)]\n",
    "\n",
    "R_Total_sqrt.dropna(inplace= True)\n",
    "U_Total_sqrt.dropna(inplace= True)\n",
    "\n",
    "anderson_R_Total_sqrt = stats.anderson(R_Total_sqrt)\n",
    "anderson_U_Total_sqrt = stats.anderson(U_Total_sqrt)\n",
    "Anderson(anderson_R_Total_sqrt)\n",
    "print()\n",
    "Anderson(anderson_U_Total_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- رد میمونه "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "با توجه به نتایج میشه با درصد اطمینان بالایی گفت که فرض صفر رد میشه چه در به تفکیک سال و چه در طول 4 سال"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
